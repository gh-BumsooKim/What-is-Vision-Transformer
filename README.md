# What is ViT(Vision Transformer)
Description and Pytorch Implementation of ViT(Vision Transformer) *(Last Update 21.09.12)*

## Index

**1. [Transformer in NLP(Natural Language Processing)](#Transformer)**<br>
**2. [ViT(Vision Transformer)](#Vit-Vision-Transformer)**<br>
**3. [Swin-Transformer](#Swin-Transformer)**<br>

## 1. Transformer?

Paper : [Attention Is All You Need](https://arxiv.org/abs/1706.03762)

<details>
<summary>Detail Description about Transformer</summary>
<div markdown="10">

Transformer란, 자연어 처리(NLP) 분야에서 사용되는 모델로 기존의 RNN 형태의 모델과 다르게 Encoding, Decoding 구조를 가진다.

</div>
</details>

<details>
<summary>Detail Implementation about Transformer</summary>
<div markdown="11">

TBA

</div>
</details>

## 2. ViT(Vision Transformer)?

Paper : [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)

<details>
<summary>Detail Description about ViT</summary>
<div markdown="20">

ViT란, 자연어 처리(NLP) 분야에서 사용되던 Transformer 모델의 구조를 객체 인식과 같은 비전(Vision) 분야 테스크에 맞도록 개선하여 적용한 모델이다.

</div>
</details>

<details>
<summary>Detail Implementation about ViT</summary>
<div markdown="21">

TBA

</div>
</details>

## 3. Swin-Transformer?

Paper : [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030)

<details>
<summary>Detail Description about Swin-Transformer</summary>
<div markdown="30">
  
Swin-Transformer란, 기존의 ViT의 문제점을 개선한 모델이다.

</div>
</details>

<details>
<summary>Detail Implementation about Swin-Transformer</summary>
<div markdown="31">

TBA

</div>
</details>
